{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pandas.io.json import json_normalize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "path = '/Users/eadaoinburgess/Desktop/Data/JSONDonegal'\n",
    "\n",
    "for JSONContent in glob.glob(path + \"/*JSONDonegal\"):\n",
    "    with open(JSONContent) as json_data:\n",
    "        data = json.load(json_data)\n",
    "        \n",
    "       #normalising the json file into a dataframe\n",
    "        hourly_data = json_normalize(data = data,\n",
    "                      record_path = ['hourly', 'data'],\n",
    "                      meta = ['latitude', 'longitude', 'flags', 'offset'], \n",
    "                      errors='ignore')\n",
    "        #converting the hex time into normal\n",
    "        hourly_data['time']= pd.to_datetime(hourly_data['time'],unit='s')\n",
    "        hourly_data['time']=pd.to_datetime(hourly_data['time'])\n",
    "        #creating seperate column for both time and date \n",
    "        hourly_data['new_date'] = [d.date() for d in hourly_data['time']]\n",
    "        hourly_data['new_time'] = [d.time() for d in hourly_data['time']]\n",
    "        #setting current date to the first date in the new_date column\n",
    "        current_date = hourly_data[\"new_date\"][0]\n",
    "            \n",
    "        import datetime\n",
    "        #setting the variable oneday to one day after the current date\n",
    "        oneday= current_date + datetime.timedelta(days=1)\n",
    "        #setting the variable threeday to three days after the current date\n",
    "        threeday = current_date + datetime.timedelta(days=3)\n",
    "        #setting the variable Fiveday to five days after the current date\n",
    "        fiveday= current_date + datetime.timedelta(days=5)\n",
    "          \n",
    "        #converting precipIntensity from object to a float \n",
    "        hourly_data[\"precipIntensity\"] = pd.to_numeric(hourly_data[\"precipIntensity\"])\n",
    "            \n",
    "        #as the data is hourly, we need to sum the total amount for 24 hours to get the total amount   \n",
    "        five = hourly_data.loc[hourly_data['new_date']== fiveday, 'precipIntensity'].sum()\n",
    "        three = hourly_data.loc[hourly_data['new_date']== threeday, 'precipIntensity'].sum()\n",
    "        one = hourly_data.loc[hourly_data['new_date']== oneday, 'precipIntensity'].sum()\n",
    "        \n",
    "        #creating constructer in which will be converted to a dataframe\n",
    "        data2 = {'Provider': ['DarkSky'],'Location': ['Donegal'],'One_Day_Ahead':[one],'DateOne':[oneday],'Three_Days_Ahead':[three],'DateThree': [threeday] ,'Five_Days_Ahead':[five],'DateFive': [fiveday], 'Date_Scraped': [current_date]} \n",
    "  \n",
    "\n",
    "        #Create DataFrame \n",
    "        df1 = pd.DataFrame(data2)\n",
    "        \n",
    "        import os.path as path\n",
    "        #checking if the csv file is created\n",
    "        if path.exists(\"forecastNew.csv\"):\n",
    "            #create csv file if not and add the dataframe to it \n",
    "            forecastData = pd.read_csv(\"forecastNew.csv\") \n",
    "            forecastData = forecastData.append(df1)\n",
    "            forecastData.to_csv(\"forecastNew.csv\",index=False)\n",
    "        else:\n",
    "            #append the dataframe if csv already created\n",
    "            df1.to_csv(\"forecastNew.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as above but for Dublin\n",
    "path = '/Users/eadaoinburgess/Desktop/Data/JSONDublin'\n",
    "\n",
    "for JSONContent in glob.glob(path + \"/*JSONDublin\"):\n",
    "    with open(JSONContent) as json_data:\n",
    "        data = json.load(json_data)\n",
    "        \n",
    "      \n",
    "        hourly_data = json_normalize(data = data,\n",
    "                      record_path = ['hourly', 'data'],\n",
    "                      meta = ['latitude', 'longitude', 'flags', 'offset'], \n",
    "                      errors='ignore')\n",
    "        hourly_data['time']= pd.to_datetime(hourly_data['time'],unit='s')\n",
    "        hourly_data['time']=pd.to_datetime(hourly_data['time'])\n",
    "        hourly_data['new_date'] = [d.date() for d in hourly_data['time']]\n",
    "        hourly_data['new_time'] = [d.time() for d in hourly_data['time']]\n",
    "        current_date = hourly_data[\"new_date\"][0]\n",
    "            \n",
    "        import datetime\n",
    "        oneday= current_date + datetime.timedelta(days=1)\n",
    "        threeday = current_date + datetime.timedelta(days=3)\n",
    "        fiveday= current_date + datetime.timedelta(days=5)\n",
    "          \n",
    "        \n",
    "        hourly_data[\"precipIntensity\"] = pd.to_numeric(hourly_data[\"precipIntensity\"])\n",
    "            \n",
    "        five = hourly_data.loc[hourly_data['new_date']== fiveday, 'precipIntensity'].sum()\n",
    "        three = hourly_data.loc[hourly_data['new_date']== threeday, 'precipIntensity'].sum()\n",
    "        one = hourly_data.loc[hourly_data['new_date']== oneday, 'precipIntensity'].sum()\n",
    "            \n",
    "        data2 = {'Provider': ['DarkSky'],'Location': ['Dublin'],'One_Day_Ahead':[one],'DateOne':[oneday],'Three_Days_Ahead':[three],'DateThree': [threeday] ,'Five_Days_Ahead':[five],'DateFive': [fiveday], 'Date_Scraped': [current_date]} \n",
    "  \n",
    "          \n",
    "        df1 = pd.DataFrame(data2)\n",
    "        \n",
    "        import os.path as path\n",
    "\n",
    "        if path.exists(\"forecastNew.csv\"):\n",
    "            forecastData = pd.read_csv(\"forecastNew.csv\") \n",
    "            forecastData = forecastData.append(df1)\n",
    "            forecastData.to_csv(\"forecastNew.csv\",index=False)\n",
    "        else:\n",
    "            df1.to_csv(\"forecastNew.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as above but for Mayo\n",
    "path = '/Users/eadaoinburgess/Desktop/Data/JSONMayo'\n",
    "\n",
    "for JSONContent in glob.glob(path + \"/*JSONMayo\"):\n",
    "    with open(JSONContent) as json_data:\n",
    "        data = json.load(json_data)\n",
    "        \n",
    "      \n",
    "        hourly_data = json_normalize(data = data,\n",
    "                      record_path = ['hourly', 'data'],\n",
    "                      meta = ['latitude', 'longitude', 'flags', 'offset'], \n",
    "                      errors='ignore')\n",
    "        hourly_data['time']= pd.to_datetime(hourly_data['time'],unit='s')\n",
    "        hourly_data['time']=pd.to_datetime(hourly_data['time'])\n",
    "        hourly_data['new_date'] = [d.date() for d in hourly_data['time']]\n",
    "        hourly_data['new_time'] = [d.time() for d in hourly_data['time']]\n",
    "        current_date = hourly_data[\"new_date\"][0]\n",
    "            \n",
    "        import datetime\n",
    "        oneday= current_date + datetime.timedelta(days=1)\n",
    "        threeday = current_date + datetime.timedelta(days=3)\n",
    "        fiveday= current_date + datetime.timedelta(days=5)\n",
    "          \n",
    "        \n",
    "        hourly_data[\"precipIntensity\"] = pd.to_numeric(hourly_data[\"precipIntensity\"])\n",
    "            \n",
    "        five = hourly_data.loc[hourly_data['new_date']== fiveday, 'precipIntensity'].sum()\n",
    "        three = hourly_data.loc[hourly_data['new_date']== threeday, 'precipIntensity'].sum()\n",
    "        one = hourly_data.loc[hourly_data['new_date']== oneday, 'precipIntensity'].sum()\n",
    "            \n",
    "        data2 = {'Provider': ['DarkSky'],'Location': ['Mayo'],'One_Day_Ahead':[one],'DateOne':[oneday],'Three_Days_Ahead':[three],'DateThree': [threeday] ,'Five_Days_Ahead':[five],'DateFive': [fiveday], 'Date_Scraped': [current_date]} \n",
    "  \n",
    "          \n",
    "        df1 = pd.DataFrame(data2)\n",
    "        \n",
    "        import os.path as path\n",
    "\n",
    "        if path.exists(\"forecastNew.csv\"):\n",
    "            forecastData = pd.read_csv(\"forecastNew.csv\") \n",
    "            forecastData = forecastData.append(df1)\n",
    "            forecastData.to_csv(\"forecastNew.csv\",index=False)\n",
    "        else:\n",
    "            df1.to_csv(\"forecastNew.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as above but for Wexford\n",
    "path = '/Users/eadaoinburgess/Desktop/Data/JSONWexford'\n",
    "\n",
    "for JSONContent in glob.glob(path + \"/*JSONWexford\"):\n",
    "    with open(JSONContent) as json_data:\n",
    "        data = json.load(json_data)\n",
    "        \n",
    "       \n",
    "        hourly_data = json_normalize(data = data,\n",
    "                      record_path = ['hourly', 'data'],\n",
    "                      meta = ['latitude', 'longitude', 'flags', 'offset'], \n",
    "                      errors='ignore')\n",
    "        hourly_data['time']= pd.to_datetime(hourly_data['time'],unit='s')\n",
    "        hourly_data['time']=pd.to_datetime(hourly_data['time'])\n",
    "        hourly_data['new_date'] = [d.date() for d in hourly_data['time']]\n",
    "        hourly_data['new_time'] = [d.time() for d in hourly_data['time']]\n",
    "        current_date = hourly_data[\"new_date\"][0]\n",
    "            \n",
    "        import datetime\n",
    "        oneday= current_date + datetime.timedelta(days=1)\n",
    "        threeday = current_date + datetime.timedelta(days=3)\n",
    "        fiveday= current_date + datetime.timedelta(days=5)\n",
    "          \n",
    "        \n",
    "        hourly_data[\"precipIntensity\"] = pd.to_numeric(hourly_data[\"precipIntensity\"])\n",
    "            \n",
    "        five = hourly_data.loc[hourly_data['new_date']== fiveday, 'precipIntensity'].sum()\n",
    "        three = hourly_data.loc[hourly_data['new_date']== threeday, 'precipIntensity'].sum()\n",
    "        one = hourly_data.loc[hourly_data['new_date']== oneday, 'precipIntensity'].sum()\n",
    "            \n",
    "        data2 = {'Provider': ['DarkSky'],'Location': ['Wexford'],'One_Day_Ahead':[one],'DateOne':[oneday],'Three_Days_Ahead':[three],'DateThree': [threeday] ,'Five_Days_Ahead':[five],'DateFive': [fiveday], 'Date_Scraped': [current_date]} \n",
    "  \n",
    "         \n",
    "        df1 = pd.DataFrame(data2)\n",
    "        \n",
    "        import os.path as path\n",
    "\n",
    "        if path.exists(\"forecastNew.csv\"):\n",
    "            forecastData = pd.read_csv(\"forecastNew.csv\") \n",
    "            forecastData = forecastData.append(df1)\n",
    "            forecastData.to_csv(\"forecastNew.csv\",index=False)\n",
    "        else:\n",
    "            df1.to_csv(\"forecastNew.csv\",index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
